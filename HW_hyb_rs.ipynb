{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что делать?  \n",
    "\n",
    "1.Датасет ml-latest  \n",
    "2.Вспомнить подходы, которые мы разбирали  \n",
    "3.Выбрать понравившийся подход к гибридным системам  \n",
    "4.Написать свою  \n",
    "\n",
    "Материалы здесь: https://github.com/ALKONDR/netology-recsys/blob/master/lecture-5/lecture-5-part-2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('links.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "tags = pd.read_csv('tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_ratings = movies.join(ratings.set_index('movieId'), on='movieId').reset_index(drop=True)\n",
    "movies_with_ratings.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_with_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({\n",
    "    'uid': movies_with_ratings.userId,\n",
    "    'iid': movies_with_ratings.title,\n",
    "    'rating': movies_with_ratings.rating\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(dataset, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x26050454af0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "algo_1 = SVD(n_factors=20, n_epochs=20)\n",
    "algo_1.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_1 = algo_1.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8708154840990902"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(test_pred_1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Wall time: 17.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x2605048c9d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "algo_2 = KNNWithMeans(k=20, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "algo_2.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_2 = algo_2.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8739785042204141"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(test_pred_2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x260502b6310>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "algo_3 = SVDpp()\n",
    "algo_3.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_3 = algo_3.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8583040210997777"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(test_pred_3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.slope_one.SlopeOne at 0x260503d4070>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "algo_4 = SlopeOne()\n",
    "algo_4.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_4 = algo_4.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8959120981252762"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(test_pred_4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_df  = dataset.copy().drop(['uid','iid'], axis=1)\n",
    "\n",
    "for tqdm_notebook(index, row in dataset.iterrows()):\n",
    "    predicts_df.loc[index,'algo_1'] = algo_1.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    predicts_df.loc[index,'algo_2'] = algo_2.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    predicts_df.loc[index,'algo_3'] = algo_3.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    predicts_df.loc[index,'algo_4'] = algo_4.predict(uid=row['uid'], iid=row['iid']).est\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = predicts_df.drop('rating',axis=1)\n",
    "y = predicts_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_5 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = algo_5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_final = np.sqrt(mean_squared_error(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_recommendation(user_id, item_id):\n",
    "    predictions = pd.DataFrame()\n",
    "    \n",
    "    predictions.loc[0,'algo_1'] = algo_1.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    predictions.loc[0,'algo_2'] = algo_2.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    predictions.loc[0,'algo_3'] = algo_3.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    predictions.loc[0,'algo_4'] = algo_4.predict(uid=row['uid'], iid=row['iid']).est\n",
    "    \n",
    "    fnal_est = algo_5.predict(predictions)\n",
    "    \n",
    "    return fnal_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.95768502])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_recommendation(184,'Toy Story (1995)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказан рейтинг конкретного фильма для конкретного пользователя при помощи стакинга моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# метарекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts_df['algo_1_r'] = np.abs(predicts_df['algo_1'] - predicts_df['rating'])\n",
    "# predicts_df['algo_2_r'] = np.abs(predicts_df['algo_2'] - predicts_df['rating'])\n",
    "# predicts_df['algo_3_r'] = np.abs(predicts_df['algo_3'] - predicts_df['rating'])\n",
    "# predicts_df['algo_4_r'] = np.abs(predicts_df['algo_4'] - predicts_df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts_df['true_algo'] = predicts_df.copy().loc[:,['algo_1_r','algo_2_r','algo_3_r','algo_4_r']].idxmin(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = predicts_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.join(dataset.drop('rating', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>algo_1</th>\n",
       "      <th>algo_2</th>\n",
       "      <th>algo_3</th>\n",
       "      <th>algo_4</th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.631020</td>\n",
       "      <td>4.437411</td>\n",
       "      <td>4.743843</td>\n",
       "      <td>4.688279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.810775</td>\n",
       "      <td>4.031528</td>\n",
       "      <td>3.877734</td>\n",
       "      <td>3.859359</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.441314</td>\n",
       "      <td>4.135260</td>\n",
       "      <td>3.368667</td>\n",
       "      <td>3.686063</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.684760</td>\n",
       "      <td>2.935026</td>\n",
       "      <td>3.397402</td>\n",
       "      <td>3.670467</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.082983</td>\n",
       "      <td>4.296729</td>\n",
       "      <td>4.247865</td>\n",
       "      <td>4.143816</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating    algo_1    algo_2    algo_3    algo_4   uid               iid\n",
       "0     4.0  4.631020  4.437411  4.743843  4.688279   1.0  Toy Story (1995)\n",
       "1     4.0  3.810775  4.031528  3.877734  3.859359   5.0  Toy Story (1995)\n",
       "2     4.5  3.441314  4.135260  3.368667  3.686063   7.0  Toy Story (1995)\n",
       "3     2.5  3.684760  2.935026  3.397402  3.670467  15.0  Toy Story (1995)\n",
       "4     4.5  4.082983  4.296729  4.247865  4.143816  17.0  Toy Story (1995)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-236-f67261a6bfba>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for user_id, group in tqdm_notebook(pred_df.groupby('uid')):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07c1ce4c0764eb9842cbdc333b9fc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=610.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_algo_for_user_dict = {}\n",
    "\n",
    "for user_id, group in tqdm_notebook(pred_df.groupby('uid')):\n",
    "    rmse_list = []\n",
    "    \n",
    "    rmse_list.append(np.sqrt(mean_squared_error(group['rating'], group['algo_1'])))\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(group['rating'], group['algo_2'])))\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(group['rating'], group['algo_3'])))\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(group['rating'], group['algo_4'])))\n",
    "    \n",
    "    best_algo_for_user_index = np.array(rmse_list).argmin()\n",
    "    \n",
    "    best_algo_for_user_dict.setdefault(user_id,(f'algo_{best_algo_for_user_index+1}'))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'algo_1' : algo_1, \n",
    "    'algo_2' : algo_2, \n",
    "    'algo_3' : algo_3, \n",
    "    'algo_4' : algo_4, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'algo_2'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_algo_for_user_dict.get(184)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_algo_recommendation(user_id, item_id):\n",
    "    best_algo = best_algo_for_user_dict.get(user_id)\n",
    "\n",
    "    pred_rait = models_dict.get(best_algo).predict(user_id, item_id)\n",
    "    \n",
    "    return pred_rait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=184, iid='Toy Story (1995)', r_ui=None, est=4.5419459385279914, details={'actual_k': 20, 'was_impossible': False})"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_algo_recommendation(184,'Toy Story (1995)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_coo = coo_matrix(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-537bf31261ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_train_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_coo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_percentage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\frenzzzzy\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightfm\\cross_validation.py\u001b[0m in \u001b[0;36mrandom_train_test_split\u001b[1;34m(interactions, test_percentage, random_state)\u001b[0m\n\u001b[0;32m     62\u001b[0m                         interactions.data)\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mcutoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtest_percentage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\frenzzzzy\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\lightfm\\cross_validation.py\u001b[0m in \u001b[0;36m_shuffle\u001b[1;34m(uids, iids, data, random_state)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mshuffle_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffle_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     return (uids[shuffle_indices],\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'shuffle'"
     ]
    }
   ],
   "source": [
    "train, test = random_train_test_split(dataset_coo, test_percentage=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM()\n",
    "model.fit(train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "\n",
    "model.fit_partial(train, epochs=10)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "    n_users, n_items = data['train'].shape\n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()                                    \n",
    "                          [user_id].indices]\n",
    "        \n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "        \n",
    "        print(\"     Recommended:\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_recommendation(model, movielens, [10, 25, 451])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
